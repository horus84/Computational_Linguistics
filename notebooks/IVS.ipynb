{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "scf6K822Zbfm",
        "outputId": "85bb8ae0-88d1-4219-a223-4759fbd5a902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/165.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m163.8/165.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/inscriptions.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-692745105>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 1) Load inscriptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/inscriptions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mdf_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'complete'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/inscriptions.csv'"
          ]
        }
      ],
      "source": [
        "# Updated IVS Pipeline with Improvements: BiLSTM, Dropout, Generation\n",
        "\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn hmmlearn fuzzywuzzy python-Levenshtein tensorflow opencv-python -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from hmmlearn import hmm\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "import cv2\n",
        "\n",
        "# 1) Load inscriptions\n",
        "df = pd.read_csv('/content/inscriptions.csv')\n",
        "df_complete = df[df['complete'] == 'Y'].copy()\n",
        "\n",
        "def parse_sequence(text):\n",
        "    if not isinstance(text, str): return []\n",
        "    signs = text.strip('+').split('-')\n",
        "    return [s for s in signs if s not in ('000','999')]\n",
        "\n",
        "sequences = [seq for seq in df_complete['text'].apply(parse_sequence).tolist() if seq]\n",
        "all_signs = sorted({s for seq in sequences for s in seq})\n",
        "sign_to_idx = {s:i for i,s in enumerate(all_signs)}\n",
        "idx_to_sign = {i:s for s,i in sign_to_idx.items()}\n",
        "\n",
        "# 2) Co-occurrence & Clustering\n",
        "N = len(all_signs)\n",
        "co_occur = np.zeros((N,N), int)\n",
        "for seq in sequences:\n",
        "    for a,b in zip(seq, seq[1:]):\n",
        "        co_occur[sign_to_idx[a], sign_to_idx[b]] += 1\n",
        "\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(co_occur)\n",
        "sign_to_cluster = {s:kmeans.labels_[sign_to_idx[s]] for s in all_signs}\n",
        "\n",
        "# 3) Image Verification\n",
        "def verify_images(df, json_map='/content/seal_id_and_image_mapping.json',\n",
        "                  img_dir='/content/seal_images', ngram=('002','861'), sample_n=5):\n",
        "    with open(json_map) as f:\n",
        "        image_map = json.load(f)\n",
        "    ngram_str = '-'.join(ngram)\n",
        "    df_ng = df[df['text'].str.contains(ngram_str, na=False)]\n",
        "    print(f\"Found {len(df_ng)} inscriptions with 3-gram {ngram_str}.\")\n",
        "\n",
        "    out = []\n",
        "    for _,row in df_ng.head(sample_n).iterrows():\n",
        "        seal_id = str(row['id'])\n",
        "        cisi    = str(row.get('cisi',''))\n",
        "        site    = row.get('site','')\n",
        "\n",
        "        prefix = {'Alamgirpur':'Agr-','Allahdino':'Ad-','Harappa':'H-',\n",
        "                  'Mohenjo-daro':'M-','Dholavira':'D-','Lothal':'L-',\n",
        "                  'Kalibangan':'K-','Amri':'Amri-','Banawali':'B-',\n",
        "                  'Chanhu-daro':'C-'}.get(site,'H-')\n",
        "        key = cisi if cisi and cisi!='-' else f\"{prefix}{seal_id}\".split('.')[0]\n",
        "\n",
        "        imgs = image_map.get(key)\n",
        "        if imgs is None:\n",
        "            best = process.extractOne(key, list(image_map.keys()))\n",
        "            if best and best[1]>80:\n",
        "                print(f\"Fuzzy: {key} → {best[0]} ({best[1]}%)\")\n",
        "                imgs = image_map[best[0]]\n",
        "            else:\n",
        "                imgs = []\n",
        "\n",
        "        filepaths = [os.path.join(img_dir,f) for f in imgs if os.path.exists(os.path.join(img_dir,f))]\n",
        "        filepaths = filepaths or ['<no file found>']\n",
        "        out.append({'seal_id': seal_id, 'ngram_match': row['text'],\n",
        "                    'lookup_key': key, 'images_on_disk': filepaths})\n",
        "\n",
        "    sample_df = pd.DataFrame(out)\n",
        "    sample_df.to_csv('/content/image_verification_samples.csv', index=False)\n",
        "    print(\"Saved samples to /content/image_verification_samples.csv\")\n",
        "    return sample_df\n",
        "\n",
        "# 4) HMM Training\n",
        "def train_hmm(sequences, sign_to_cluster, n_states=5):\n",
        "    print(\"Training HMM…\")\n",
        "    cluster_seqs = [[sign_to_cluster[s] for s in seq] for seq in sequences]\n",
        "    X = np.concatenate(cluster_seqs).reshape(-1,1)\n",
        "    lengths = list(map(len, cluster_seqs))\n",
        "    model = hmm.MultinomialHMM(n_components=n_states, n_iter=100, random_state=42)\n",
        "    model.fit(X, lengths)\n",
        "    print(\"Transition matrix (first 5×5):\")\n",
        "    print(model.transmat_[:5,:5])\n",
        "    return model\n",
        "\n",
        "# 5) RNN Training & Generation\n",
        "def train_rnn(sequences, sign_to_idx, max_len=10, emb=64, lstm_u=128, epochs=15):\n",
        "    print(\"Preparing RNN data…\")\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(1, len(seq)):\n",
        "            X.append([sign_to_idx[s] for s in seq[:i]])\n",
        "            y.append(sign_to_idx[seq[i]])\n",
        "\n",
        "    X_pad = pad_sequences(X, maxlen=max_len, padding='pre', dtype='int32')\n",
        "    y_arr = np.array(y, dtype='int32')\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=len(sign_to_idx), output_dim=emb),\n",
        "        Bidirectional(LSTM(lstm_u, return_sequences=False)),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(sign_to_idx), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Training RNN…\")\n",
        "    model.fit(X_pad, y_arr, epochs=epochs, batch_size=32, verbose=1)\n",
        "    print(\"RNN training complete.\")\n",
        "    return model\n",
        "\n",
        "def generate_sequence(model, seed_seq, sign_to_idx, idx_to_sign, max_len=10, steps=5):\n",
        "    seq = [sign_to_idx.get(s, 0) for s in seed_seq]\n",
        "    for _ in range(steps):\n",
        "        padded = pad_sequences([seq], maxlen=max_len, padding='pre')\n",
        "        pred = model.predict(padded, verbose=0)\n",
        "        next_idx = np.argmax(pred)\n",
        "        seq.append(next_idx)\n",
        "    return [idx_to_sign[i] for i in seq]\n",
        "\n",
        "# 6) Run full pipeline\n",
        "if __name__ == '__main__':\n",
        "    print(\"== IVS Breakthrough Analysis ==\")\n",
        "    samples = verify_images(df_complete)\n",
        "    hmm_model = train_hmm(sequences, sign_to_cluster)\n",
        "    rnn_model = train_rnn(sequences, sign_to_idx)\n",
        "\n",
        "    print(\"\\nSample Generation:\")\n",
        "    print(\"Seed: ['002','861'] →\", generate_sequence(rnn_model, ['002','861'], sign_to_idx, idx_to_sign))\n",
        "    print(\"\\n-- Done. --\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Paths: adjust if needed\n",
        "INS_CSV = '/content/inscriptions.csv'\n",
        "IMG_DIR = '/content/seal_images'                   # where you extracted seal_images.zip\n",
        "JSON_MAP = '/content/seal_id_and_image_mapping.json'\n",
        "\n",
        "# 2) Load data\n",
        "df = pd.read_csv(INS_CSV)\n",
        "df = df[df['complete']=='Y']  # only complete\n",
        "with open(JSON_MAP) as f:\n",
        "    image_map = json.load(f)\n",
        "\n",
        "# 3) Find inscriptions with your n-gram\n",
        "ngram = '002-861'\n",
        "matches = df[df['text'].str.contains(ngram, na=False)]\n",
        "\n",
        "# 4) Prepare to plot up to 4 examples\n",
        "fig, axes = plt.subplots(2,2, figsize=(10,10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "site_prefix = {\n",
        "  'Alamgirpur':'Agr','Allahdino':'Ad','Harappa':'H',\n",
        "  'Mohenjo-daro':'M','Dholavira':'D','Lothal':'L',\n",
        "  'Kalibangan':'K','Amri':'Amri','Banawali':'B',\n",
        "  'Chanhu-daro':'C'\n",
        "}\n",
        "\n",
        "for ax, (_, row) in zip(axes, matches.head(4).iterrows()):\n",
        "    # derive lookup key exactly as in your data\n",
        "    cisi = str(row.get('cisi','-'))\n",
        "    if cisi!='-':\n",
        "        key = cisi\n",
        "    else:\n",
        "        prefix = site_prefix.get(row['site'],'H')\n",
        "        key = f\"{prefix}-{int(row['id'])}\"\n",
        "    key = key.split('.')[0]\n",
        "\n",
        "    files = image_map.get(key, [])\n",
        "    if not files:\n",
        "        ax.set_title(f\"{key} – no image\")\n",
        "        ax.axis('off')\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(IMG_DIR, files[0])\n",
        "    if not os.path.exists(img_path):\n",
        "        ax.set_title(f\"{key} – file missing\")\n",
        "        ax.axis('off')\n",
        "        continue\n",
        "\n",
        "    # Load and edge-detect\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 75, 150)\n",
        "\n",
        "    # Overlay red edges\n",
        "    overlay = img.copy()\n",
        "    overlay[edges>0] = [255,0,0]\n",
        "    overlay = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    ax.imshow(overlay)\n",
        "    ax.set_title(f\"Seal {key}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "O6qPwqdqgIEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IVS Training Pipeline with Image-Verified Filtering (Fixed dtype bug)\n",
        "\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn hmmlearn fuzzywuzzy python-Levenshtein tensorflow opencv-python -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "from hmmlearn import hmm\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "# Paths\n",
        "INS_CSV = '/content/inscriptions.csv'\n",
        "JSON_MAP = '/content/seal_id_and_image_mapping.json'\n",
        "\n",
        "# Load data\n",
        "with open(JSON_MAP) as f:\n",
        "    image_map = json.load(f)\n",
        "\n",
        "df = pd.read_csv(INS_CSV)\n",
        "df_complete = df[df['complete'] == 'Y'].copy()\n",
        "\n",
        "# Seal prefix mapping from site\n",
        "site_prefix_map = {\n",
        "    'Alamgirpur': 'Agr', 'Allahdino': 'Ad', 'Harappa': 'H', 'Mohenjo-daro': 'M',\n",
        "    'Dholavira': 'D', 'Lothal': 'L', 'Kalibangan': 'K', 'Amri': 'Amri',\n",
        "    'Banawali': 'B', 'Chanhu-daro': 'C'\n",
        "}\n",
        "\n",
        "def compute_seal_key(row):\n",
        "    if pd.notna(row.get('cisi')) and row['cisi'] != '-':\n",
        "        return str(row['cisi']).split('.')[0]\n",
        "    site_prefix = site_prefix_map.get(row['site'], 'H')\n",
        "    return f\"{site_prefix}-{int(row['id'])}\"\n",
        "\n",
        "df_complete['seal_key'] = df_complete.apply(compute_seal_key, axis=1)\n",
        "df_complete = df_complete[df_complete['seal_key'].isin(image_map)]\n",
        "\n",
        "# Parse sequences\n",
        "def parse_sequence(text):\n",
        "    if not isinstance(text, str): return []\n",
        "    return [s for s in text.strip('+').split('-') if s not in ('000','999')]\n",
        "\n",
        "sequences = [parse_sequence(row['text']) for _, row in df_complete.iterrows()]\n",
        "sequences = [seq for seq in sequences if seq]\n",
        "\n",
        "# Sign vocabulary\n",
        "all_signs = sorted({s for seq in sequences for s in seq})\n",
        "sign_to_idx = {s:i for i,s in enumerate(all_signs)}\n",
        "idx_to_sign = {i:s for s,i in sign_to_idx.items()}\n",
        "\n",
        "# Co-occurrence matrix for clustering\n",
        "N = len(all_signs)\n",
        "co_occur = np.zeros((N,N), int)\n",
        "for seq in sequences:\n",
        "    for a,b in zip(seq, seq[1:]):\n",
        "        co_occur[sign_to_idx[a], sign_to_idx[b]] += 1\n",
        "\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(co_occur)\n",
        "sign_to_cluster = {s: kmeans.labels_[sign_to_idx[s]] for s in all_signs}\n",
        "\n",
        "# HMM Training\n",
        "def train_hmm(sequences, sign_to_cluster, n_states=5):\n",
        "    cluster_seqs = [[sign_to_cluster[s] for s in seq] for seq in sequences]\n",
        "    X = np.concatenate(cluster_seqs).reshape(-1,1)\n",
        "    lengths = [len(seq) for seq in cluster_seqs]\n",
        "    model = hmm.MultinomialHMM(n_components=n_states, n_iter=100, random_state=42)\n",
        "    model.fit(X, lengths)\n",
        "    print(\"Transition matrix (5x5):\")\n",
        "    print(model.transmat_[:5,:5])\n",
        "    return model\n",
        "\n",
        "# RNN Training\n",
        "\n",
        "def train_rnn(sequences, sign_to_idx, max_len=10, emb=64, lstm_u=128, epochs=15):\n",
        "    print(\"Preparing RNN data…\")\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(1, len(seq)):\n",
        "            X.append([sign_to_idx[s] for s in seq[:i]])\n",
        "            y.append(sign_to_idx[seq[i]])\n",
        "\n",
        "    X_pad = pad_sequences(X, maxlen=max_len, padding='pre', dtype='int32')\n",
        "    y_arr = np.array(y, dtype='int32')\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=len(sign_to_idx), output_dim=emb),\n",
        "        Bidirectional(LSTM(lstm_u, return_sequences=False)),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(sign_to_idx), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"Training RNN…\")\n",
        "    model.fit(X_pad, y_arr, epochs=epochs, batch_size=32, verbose=1)\n",
        "    print(\"RNN training complete.\")\n",
        "    return model\n",
        "\n",
        "# Sequence generation\n",
        "\n",
        "def generate_sequence(model, seed_seq, sign_to_idx, idx_to_sign, max_len=10, steps=5):\n",
        "    seq = [sign_to_idx.get(s, 0) for s in seed_seq]\n",
        "    for _ in range(steps):\n",
        "        padded = pad_sequences([seq], maxlen=max_len, padding='pre', dtype='int32')\n",
        "        pred = model.predict(padded, verbose=0)\n",
        "        seq.append(int(np.argmax(pred)))\n",
        "    return [idx_to_sign[i] for i in seq]\n",
        "\n",
        "# Main\n",
        "if __name__ == '__main__':\n",
        "    print(\"== IVS Training with Verified Seals ==\")\n",
        "    print(f\"Training set size (with images): {len(sequences)} inscriptions\")\n",
        "    hmm_model = train_hmm(sequences, sign_to_cluster)\n",
        "    rnn_model = train_rnn(sequences, sign_to_idx)\n",
        "    example = generate_sequence(rnn_model, ['002','861'], sign_to_idx, idx_to_sign)\n",
        "    print(\"Sample RNN generation from ['002','861'] →\", example)\n",
        "    print(\"-- Done --\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYbvs5bqkbBv",
        "outputId": "37340f72-2c1e-4d11-b2d4-1b93a471b5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.hmm:MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
            "https://github.com/hmmlearn/hmmlearn/issues/335\n",
            "https://github.com/hmmlearn/hmmlearn/issues/340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== IVS Training with Verified Seals ==\n",
            "Training set size (with images): 2229 inscriptions\n",
            "Transition matrix (5x5):\n",
            "[[8.70151441e-09 9.57991900e-01 4.67909026e-04 6.13749857e-03\n",
            "  3.54026835e-02]\n",
            " [4.49658654e-01 1.11593150e-02 1.03467823e-01 1.66438227e-03\n",
            "  4.34049826e-01]\n",
            " [5.33469414e-07 9.30104465e-01 1.20106772e-03 6.86815374e-02\n",
            "  1.23965099e-05]\n",
            " [2.08310540e-08 5.02686400e-04 1.27469100e-03 2.11558240e-02\n",
            "  9.77066778e-01]\n",
            " [9.34237752e-01 5.89179961e-02 4.18444294e-06 1.45917726e-07\n",
            "  6.83992132e-03]]\n",
            "Preparing RNN data…\n",
            "Training RNN…\n",
            "Epoch 1/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.0527 - loss: 5.4817\n",
            "Epoch 2/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.0933 - loss: 4.7561\n",
            "Epoch 3/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.1432 - loss: 4.3241\n",
            "Epoch 4/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.1763 - loss: 4.0126\n",
            "Epoch 5/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.2167 - loss: 3.7710\n",
            "Epoch 6/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.2572 - loss: 3.5127\n",
            "Epoch 7/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 67ms/step - accuracy: 0.2894 - loss: 3.3280\n",
            "Epoch 8/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 34ms/step - accuracy: 0.3045 - loss: 3.1746\n",
            "Epoch 9/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.3173 - loss: 3.0661\n",
            "Epoch 10/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.3247 - loss: 2.9597\n",
            "Epoch 11/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.3480 - loss: 2.8365\n",
            "Epoch 12/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.3592 - loss: 2.7672\n",
            "Epoch 13/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.3743 - loss: 2.7050\n",
            "Epoch 14/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.3834 - loss: 2.6087\n",
            "Epoch 15/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.4056 - loss: 2.4800\n",
            "RNN training complete.\n",
            "Sample RNN generation from ['002','861'] → ['002', '861', '698', '440', '741', '920', '920']\n",
            "-- Done --\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IVS Training Pipeline with Image-Verified Filtering (Fixed dtype bug)\n",
        "\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn hmmlearn fuzzywuzzy python-Levenshtein tensorflow opencv-python -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "from hmmlearn import hmm\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "# Paths\n",
        "INS_CSV = '/content/inscriptions.csv'\n",
        "JSON_MAP = '/content/seal_id_and_image_mapping.json'\n",
        "IMG_DIR = '/content/seal_images/seal_images'\n",
        "\n",
        "# Load data\n",
        "with open(JSON_MAP) as f:\n",
        "    image_map = json.load(f)\n",
        "\n",
        "df = pd.read_csv(INS_CSV)\n",
        "df_complete = df[df['complete'] == 'Y'].copy()\n",
        "\n",
        "# Seal prefix mapping from site\n",
        "site_prefix_map = {\n",
        "    'Alamgirpur': 'Agr', 'Allahdino': 'Ad', 'Harappa': 'H', 'Mohenjo-daro': 'M',\n",
        "    'Dholavira': 'D', 'Lothal': 'L', 'Kalibangan': 'K', 'Amri': 'Amri',\n",
        "    'Banawali': 'B', 'Chanhu-daro': 'C'\n",
        "}\n",
        "\n",
        "def compute_seal_key(row):\n",
        "    if pd.notna(row.get('cisi')) and row['cisi'] != '-':\n",
        "        return str(row['cisi']).split('.')[0]\n",
        "    site_prefix = site_prefix_map.get(row['site'], 'H')\n",
        "    return f\"{site_prefix}-{int(row['id'])}\"\n",
        "\n",
        "df_complete['seal_key'] = df_complete.apply(compute_seal_key, axis=1)\n",
        "df_complete = df_complete[df_complete['seal_key'].isin(image_map)]\n",
        "\n",
        "# Parse and Normalize Sequences (Allomorph Grouping)\n",
        "def normalize_sign(s):\n",
        "    if s.startswith('002'): return '002'\n",
        "    if s.startswith('861'): return '861'\n",
        "    return s\n",
        "\n",
        "def parse_sequence(text):\n",
        "    if not isinstance(text, str): return []\n",
        "    raw = [s for s in text.strip('+').split('-') if s not in ('000','999')]\n",
        "    return [normalize_sign(s) for s in raw]\n",
        "\n",
        "sequences = [parse_sequence(row['text']) for _, row in df_complete.iterrows()]\n",
        "sequences = [seq for seq in sequences if seq]\n",
        "\n",
        "# Sign vocabulary (post-normalization)\n",
        "all_signs = sorted({s for seq in sequences for s in seq})\n",
        "sign_to_idx = {s:i for i,s in enumerate(all_signs)}\n",
        "idx_to_sign = {i:s for s,i in sign_to_idx.items()}\n",
        "\n",
        "# Co-occurrence matrix for clustering\n",
        "N = len(all_signs)\n",
        "co_occur = np.zeros((N,N), int)\n",
        "for seq in sequences:\n",
        "    for a,b in zip(seq, seq[1:]):\n",
        "        co_occur[sign_to_idx[a], sign_to_idx[b]] += 1\n",
        "\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(co_occur)\n",
        "sign_to_cluster = {s: kmeans.labels_[sign_to_idx[s]] for s in all_signs}\n",
        "\n",
        "# HMM Training\n",
        "def train_hmm(sequences, sign_to_cluster, n_states=5):\n",
        "    cluster_seqs = [[sign_to_cluster[s] for s in seq] for seq in sequences]\n",
        "    X = np.concatenate(cluster_seqs).reshape(-1,1)\n",
        "    lengths = [len(seq) for seq in cluster_seqs]\n",
        "    model = hmm.MultinomialHMM(n_components=n_states, n_iter=100, random_state=42)\n",
        "    model.fit(X, lengths)\n",
        "    print(\"Transition matrix (5x5):\")\n",
        "    print(model.transmat_[:5,:5])\n",
        "    return model\n",
        "\n",
        "# RNN Training\n",
        "def train_rnn(sequences, sign_to_idx, max_len=10, emb=64, lstm_u=128, epochs=15):\n",
        "    print(\"Preparing RNN data…\")\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(1, len(seq)):\n",
        "            X.append([sign_to_idx[s] for s in seq[:i]])\n",
        "            y.append(sign_to_idx[seq[i]])\n",
        "\n",
        "    X_pad = pad_sequences(X, maxlen=max_len, padding='pre', dtype='int32')\n",
        "    y_arr = np.array(y, dtype='int32')\n",
        "\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=len(sign_to_idx), output_dim=emb),\n",
        "        Bidirectional(LSTM(lstm_u, return_sequences=False)),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(sign_to_idx), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(\"Training RNN…\")\n",
        "    model.fit(X_pad, y_arr, epochs=epochs, batch_size=32, verbose=1)\n",
        "    print(\"RNN training complete.\")\n",
        "    return model\n",
        "\n",
        "# Sequence generation\n",
        "def generate_sequence(model, seed_seq, sign_to_idx, idx_to_sign, max_len=10, steps=5):\n",
        "    seed = [normalize_sign(s) for s in seed_seq]\n",
        "    seq = [sign_to_idx.get(s, 0) for s in seed]\n",
        "    for _ in range(steps):\n",
        "        padded = pad_sequences([seq], maxlen=max_len, padding='pre', dtype='int32')\n",
        "        pred = model.predict(padded, verbose=0)\n",
        "        seq.append(int(np.argmax(pred)))\n",
        "    return [idx_to_sign[i] for i in seq]\n",
        "\n",
        "# Automated Sign Panel Extraction (for CNN training)\n",
        "def crop_sign_panels(img_dir, output_dir, df_verify, target_ngram='002-861'):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for _, row in df_verify.iterrows():\n",
        "        key = row['lookup_key']\n",
        "        imgs = image_map.get(key, [])\n",
        "        for fname in imgs:\n",
        "            src = os.path.join(img_dir, fname)\n",
        "            if not os.path.exists(src): continue\n",
        "            img = cv2.imread(src)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            edges = cv2.Canny(gray, 50, 150)\n",
        "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
        "            for i, cnt in enumerate(contours):\n",
        "                x,y,w,h = cv2.boundingRect(cnt)\n",
        "                crop = img[y:y+h, x:x+w]\n",
        "                out_path = os.path.join(output_dir, f\"{key}_{os.path.splitext(fname)[0]}_crop{i}.png\")\n",
        "                cv2.imwrite(out_path, crop)\n",
        "    print(f\"Cropped sign panels saved to {output_dir}\")\n",
        "\n",
        "# Cluster Visualization\n",
        "def plot_clusters(sign_to_cluster, sign_to_idx):\n",
        "    from sklearn.decomposition import PCA\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    for s, idx in sign_to_idx.items():\n",
        "        vec = np.zeros(max(sign_to_cluster.values())+1)\n",
        "        vec[sign_to_cluster[s]] = 1\n",
        "        embeddings.append(vec)\n",
        "        labels.append(s)\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced = pca.fit_transform(embeddings)\n",
        "    plt.figure(figsize=(10,8))\n",
        "    scatter = plt.scatter(reduced[:,0], reduced[:,1], c=[sign_to_cluster[s] for s in labels], cmap='tab20', alpha=0.7)\n",
        "    plt.legend(*scatter.legend_elements(), title='Cluster')\n",
        "    for i, label in enumerate(labels):\n",
        "        plt.text(reduced[i, 0], reduced[i, 1], label, fontsize=6, alpha=0.75)\n",
        "    plt.title('Sign Clusters (PCA with Labels)')\n",
        "    plt.xlabel('PC1')\n",
        "    plt.ylabel('PC2')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Save normalized sequences to CSV\n",
        "normalized_records = []\n",
        "for idx, row in df_complete.iterrows():\n",
        "    normalized_records.append({\n",
        "        'seal_key': row['seal_key'],\n",
        "        'normalized_text': '-'.join(parse_sequence(row['text']))\n",
        "    })\n",
        "norm_df = pd.DataFrame(normalized_records)\n",
        "norm_df.to_csv('/content/normalized_inscriptions.csv', index=False)\n",
        "print('Saved normalized sequences to /content/normalized_inscriptions.csv')\n",
        "\n",
        "# ---- Pipeline Execution ----\n",
        "print(\"== IVS Training with Verified Seals and Allomorph Grouping ==\")\n",
        "print(f\"Training set size (with images): {len(sequences)} inscriptions\")\n",
        "hmm_model = train_hmm(sequences, sign_to_cluster)\n",
        "rnn_model = train_rnn(sequences, sign_to_idx)\n",
        "example = generate_sequence(rnn_model, ['002','861'], sign_to_idx, idx_to_sign)\n",
        "print(\"Sample RNN generation from ['002','861'] →\", example)\n",
        "plot_clusters(sign_to_cluster, sign_to_idx)\n",
        "df_verify = pd.read_csv('/content/image_verification_samples.csv')\n",
        "crop_sign_panels(IMG_DIR, '/content/sign_crops', df_verify)\n",
        "print(\"-- Pipeline complete with visual extraction and normalized CSV --\")\n",
        "\n",
        "# ---- Extended Analysis Module ----\n",
        "from collections import defaultdict\n",
        "from math import log2\n",
        "\n",
        "def compute_entropy(model, sign_to_idx):\n",
        "    n_symbols = model.emissionprob_.shape[1]\n",
        "    entropies = {}\n",
        "    for sign, idx in sign_to_idx.items():\n",
        "        if idx >= n_symbols:\n",
        "            continue  # skip if sign index out of emission matrix bounds\n",
        "        probs = model.emissionprob_[:, idx]\n",
        "        entropy = -sum(p * log2(p) for p in probs if p > 0)\n",
        "        entropies[sign] = entropy\n",
        "    return sorted(entropies.items(), key=lambda x: -x[1])\n",
        "\n",
        "def compute_pmi(sequences):\n",
        "    pair_counts = Counter()\n",
        "    single_counts = Counter()\n",
        "    total_pairs = 0\n",
        "    for seq in sequences:\n",
        "        for i in range(len(seq) - 1):\n",
        "            a, b = seq[i], seq[i+1]\n",
        "            pair_counts[(a, b)] += 1\n",
        "            single_counts[a] += 1\n",
        "            single_counts[b] += 1\n",
        "            total_pairs += 1\n",
        "    pmi = {}\n",
        "    for (a, b), count in pair_counts.items():\n",
        "        if single_counts[a] > 0 and single_counts[b] > 0:\n",
        "            pmi[(a, b)] = log2((count * total_pairs) / (single_counts[a] * single_counts[b]))\n",
        "    return sorted(pmi.items(), key=lambda x: -x[1])\n",
        "\n",
        "print(\"== Extended Statistical Analysis ==\")\n",
        "entropy_rank = compute_entropy(hmm_model, sign_to_idx)\n",
        "pmi_pairs = compute_pmi(sequences)\n",
        "\n",
        "print(\"Top 10 signs by entropy (likely content signs):\")\n",
        "for s, h in entropy_rank[:10]:\n",
        "    print(f\"{s}: H = {h:.3f}\")\n",
        "\n",
        "print(\"Top 10 2-grams by PMI (likely fixed phrases):\")\n",
        "for (a, b), val in pmi_pairs[:10]:\n",
        "    print(f\"({a}, {b}): PMI = {val:.2f}\")\n",
        "\n",
        "print(\"-- Extended analysis complete --\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0LM3OiFPwcoJ",
        "outputId": "736d4b85-e502-43f7-fb03-15b6732f3c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.hmm:MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
            "https://github.com/hmmlearn/hmmlearn/issues/335\n",
            "https://github.com/hmmlearn/hmmlearn/issues/340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved normalized sequences to /content/normalized_inscriptions.csv\n",
            "== IVS Training with Verified Seals and Allomorph Grouping ==\n",
            "Training set size (with images): 2229 inscriptions\n",
            "Transition matrix (5x5):\n",
            "[[8.70151441e-09 9.57991900e-01 4.67909026e-04 6.13749857e-03\n",
            "  3.54026835e-02]\n",
            " [4.49658654e-01 1.11593150e-02 1.03467823e-01 1.66438227e-03\n",
            "  4.34049826e-01]\n",
            " [5.33469414e-07 9.30104465e-01 1.20106772e-03 6.86815374e-02\n",
            "  1.23965099e-05]\n",
            " [2.08310540e-08 5.02686400e-04 1.27469100e-03 2.11558240e-02\n",
            "  9.77066778e-01]\n",
            " [9.34237752e-01 5.89179961e-02 4.18444294e-06 1.45917726e-07\n",
            "  6.83992132e-03]]\n",
            "Preparing RNN data…\n",
            "Training RNN…\n",
            "Epoch 1/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.0464 - loss: 5.4956\n",
            "Epoch 2/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.0996 - loss: 4.7478\n",
            "Epoch 3/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.1324 - loss: 4.3824\n",
            "Epoch 4/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.1699 - loss: 4.0718\n",
            "Epoch 5/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2210 - loss: 3.7601\n",
            "Epoch 6/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.2598 - loss: 3.5441\n",
            "Epoch 7/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.2831 - loss: 3.3236\n",
            "Epoch 8/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2999 - loss: 3.2002\n",
            "Epoch 9/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 0.3129 - loss: 3.0783\n",
            "Epoch 10/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.3325 - loss: 2.9803\n",
            "Epoch 11/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.3572 - loss: 2.8575\n",
            "Epoch 12/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.3554 - loss: 2.7581\n",
            "Epoch 13/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.3774 - loss: 2.6782\n",
            "Epoch 14/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.4075 - loss: 2.5510\n",
            "Epoch 15/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.3977 - loss: 2.5460\n",
            "RNN training complete.\n",
            "Sample RNN generation from ['002','861'] → ['002', '861', '698', '125', '632', '032', '820']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropped sign panels saved to /content/sign_crops\n",
            "-- Pipeline complete with visual extraction and normalized CSV --\n",
            "== Extended Statistical Analysis ==\n",
            "Top 10 signs by entropy (likely content signs):\n",
            "001: H = -0.000\n",
            "Top 10 2-grams by PMI (likely fixed phrases):\n",
            "(718, 815): PMI = 12.71\n",
            "(749, 479): PMI = 12.71\n",
            "(833, 528): PMI = 11.71\n",
            "(865, 685/226): PMI = 11.71\n",
            "(251, 073): PMI = 11.71\n",
            "(160, 363): PMI = 11.71\n",
            "(561, 586): PMI = 11.13\n",
            "(127, 381): PMI = 11.13\n",
            "(901, 620): PMI = 11.13\n",
            "(307, 762): PMI = 10.71\n",
            "-- Extended analysis complete --\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iv6pI9jmL23H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ace_tools -q"
      ],
      "metadata": {
        "id": "k4rJNttfMFWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# Use /mnt/data for persistent storage\n",
        "base_data = Path('/mnt/data')\n",
        "zip_path = base_data / '/content/IM_417_150_PNG.zip'\n",
        "extract_dir = base_data / 'ivs_signs_raw'\n",
        "output_base = base_data / 'ivs_signs'\n",
        "\n",
        "# 1) Unzip\n",
        "if extract_dir.exists():\n",
        "    shutil.rmtree(extract_dir)\n",
        "extract_dir.mkdir(parents=True, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "# 2) Organize into sign-labeled dirs\n",
        "if output_base.exists():\n",
        "    shutil.rmtree(output_base)\n",
        "output_base.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for img in extract_dir.glob('*.png'):\n",
        "    sign_id = img.stem.split('_')[0]  # adjust logic if needed\n",
        "    sign_dir = output_base / sign_id\n",
        "    sign_dir.mkdir(exist_ok=True)\n",
        "    shutil.copy(img, sign_dir / img.name)\n",
        "\n",
        "# 3) Summarize structure\n",
        "structure = []\n",
        "for sd in sorted(output_base.iterdir()):\n",
        "    structure.append({'sign_id': sd.name, 'num_images': len(list(sd.glob('*.png')))})\n",
        "df_structure = pd.DataFrame(structure)\n",
        "print(\"🗂️ Sign Directory Structure (Top 20)\")\n",
        "print(df_structure.head(20))\n",
        "\n",
        "# 4) Build label CSV\n",
        "records = []\n",
        "for sd in sorted(output_base.iterdir()):\n",
        "    for img in sd.glob('*.png'):\n",
        "        records.append({'filepath': str(img), 'label': sd.name})\n",
        "df_labels = pd.DataFrame(records)\n",
        "print(\"\\n🔖 Sample Labeled Dataset\")\n",
        "print(df_labels.sample(min(10, len(df_labels))))\n",
        "\n",
        "# Save CSV\n",
        "labels_csv = base_data / 'sign_labels.csv'\n",
        "df_labels.to_csv(labels_csv, index=False)\n",
        "print(f\"\\n✅ Labels CSV saved to {labels_csv}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msjRHxlzLVkf",
        "outputId": "f4040ba9-5fe7-4cc1-ac62-466b7bb7dd25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🗂️ Sign Directory Structure (Top 20)\n",
            "   sign_id  num_images\n",
            "0        1           1\n",
            "1       10           1\n",
            "2      100           1\n",
            "3      101           1\n",
            "4      102           1\n",
            "5      103           1\n",
            "6      104           1\n",
            "7      105           1\n",
            "8      106           1\n",
            "9      107           1\n",
            "10     108           1\n",
            "11     109           1\n",
            "12      11           1\n",
            "13     110           1\n",
            "14     111           1\n",
            "15     112           1\n",
            "16     113           1\n",
            "17     114           1\n",
            "18     115           1\n",
            "19     116           1\n",
            "\n",
            "🔖 Sample Labeled Dataset\n",
            "                            filepath label\n",
            "174  /mnt/data/ivs_signs/256/256.png   256\n",
            "43   /mnt/data/ivs_signs/138/138.png   138\n",
            "24   /mnt/data/ivs_signs/120/120.png   120\n",
            "257  /mnt/data/ivs_signs/330/330.png   330\n",
            "350  /mnt/data/ivs_signs/414/414.png   414\n",
            "310  /mnt/data/ivs_signs/379/379.png   379\n",
            "29   /mnt/data/ivs_signs/125/125.png   125\n",
            "15   /mnt/data/ivs_signs/112/112.png   112\n",
            "66   /mnt/data/ivs_signs/159/159.png   159\n",
            "239  /mnt/data/ivs_signs/314/314.png   314\n",
            "\n",
            "✅ Labels CSV saved to /mnt/data/sign_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# === Step 1: Dataset Configuration ===\n",
        "DATA_DIR = '/mnt/data/ivs_signs'\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# === Step 2: Load Dataset ===\n",
        "train_ds = image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "num_classes = len(train_ds.class_names)\n",
        "\n",
        "# === Step 3: Data Augmentation & Normalization ===\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "# === Step 4: Define CNN Model ===\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=IMG_SIZE + (3,)),\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu', name='embedding_layer'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# === Step 5: Compile the Model ===\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# === Step 6: Train the Model ===\n",
        "history = model.fit(train_ds, epochs=15)\n",
        "\n",
        "# === Step 7: Save the Model ===\n",
        "model.save('/mnt/data/ivs_cnn_classifier.h5')\n",
        "print(\"✅ Model saved to /mnt/data/ivs_cnn_classifier.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gPtL5DqNylT",
        "outputId": "00450812-573e-4734-fe9f-4061f1851eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 417 files belonging to 417 classes.\n",
            "Epoch 1/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.0000e+00 - loss: 6.0573\n",
            "Epoch 2/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 228ms/step - accuracy: 0.0000e+00 - loss: 6.0327\n",
            "Epoch 3/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 225ms/step - accuracy: 0.0000e+00 - loss: 6.0326\n",
            "Epoch 4/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 336ms/step - accuracy: 0.0118 - loss: 6.0322\n",
            "Epoch 5/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 239ms/step - accuracy: 0.0026 - loss: 6.0307\n",
            "Epoch 6/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 231ms/step - accuracy: 0.0000e+00 - loss: 6.0320\n",
            "Epoch 7/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 257ms/step - accuracy: 0.0076 - loss: 6.0272\n",
            "Epoch 8/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 222ms/step - accuracy: 0.0138 - loss: 6.0275\n",
            "Epoch 9/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 277ms/step - accuracy: 0.0052 - loss: 6.0062\n",
            "Epoch 10/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 270ms/step - accuracy: 0.0057 - loss: 5.9425\n",
            "Epoch 11/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 229ms/step - accuracy: 0.0026 - loss: 5.9032\n",
            "Epoch 12/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 251ms/step - accuracy: 0.0135 - loss: 5.7621\n",
            "Epoch 13/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - accuracy: 0.0075 - loss: 5.6598\n",
            "Epoch 14/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 230ms/step - accuracy: 0.0115 - loss: 5.5506\n",
            "Epoch 15/15\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 235ms/step - accuracy: 0.0153 - loss: 5.4342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved to /mnt/data/ivs_cnn_classifier.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step: Setup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step: Load model\n",
        "model = load_model('/mnt/data/ivs_cnn_classifier.h5')\n",
        "embedding_model = Model(inputs=model.input,\n",
        "                        outputs=model.get_layer('embedding_layer').output)\n",
        "\n",
        "# Step: Reload dataset (do NOT shuffle)\n",
        "DATA_DIR = '/mnt/data/ivs_signs'\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "ds = image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "class_names = ds.class_names\n",
        "\n",
        "# Step: Extract embeddings\n",
        "embeddings = []\n",
        "labels = []\n",
        "for batch, label_batch in ds:\n",
        "    emb = embedding_model.predict(batch)\n",
        "    embeddings.append(emb)\n",
        "    labels.extend(label_batch.numpy())\n",
        "\n",
        "embeddings = np.vstack(embeddings)\n",
        "sign_ids = [class_names[i] for i in labels]\n",
        "\n",
        "# Step: Save embeddings CSV\n",
        "df_embed = pd.DataFrame(embeddings)\n",
        "df_embed.insert(0, 'sign_id', sign_ids)\n",
        "df_embed.to_csv('/mnt/data/ivs_sign_embeddings.csv', index=False)\n",
        "\n",
        "# Step: PCA & t-SNE projection\n",
        "pca = PCA(n_components=2)\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42, init='pca')\n",
        "pca_proj = pca.fit_transform(embeddings)\n",
        "tsne_proj = tsne.fit_transform(embeddings)\n",
        "\n",
        "df_proj = pd.DataFrame({\n",
        "    'sign_id': sign_ids,\n",
        "    'pca_x': pca_proj[:,0],\n",
        "    'pca_y': pca_proj[:,1],\n",
        "    'tsne_x': tsne_proj[:,0],\n",
        "    'tsne_y': tsne_proj[:,1],\n",
        "})\n",
        "df_proj.to_csv('/mnt/data/ivs_embedding_projections.csv', index=False)\n",
        "\n",
        "# Step: Plot PCA\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(pca_proj[:, 0], pca_proj[:, 1], c=labels, cmap='tab20', alpha=0.7)\n",
        "plt.title('Indus Sign PCA Projection')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/mnt/data/pca_signs_plot.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "rplZ6exoPXEU",
        "outputId": "275a44fd-471e-43fc-aaaa-6de053953cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "The layer sequential_13 has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-20e7255ebd4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Step: Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/ivs_cnn_classifier.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m embedding_model = Model(inputs=model.input,\n\u001b[0m\u001b[1;32m     14\u001b[0m                         outputs=model.get_layer('embedding_layer').output)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: The layer sequential_13 has never been called and thus has no defined input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries in Colab\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn hmmlearn fuzzywuzzy python-Levenshtein tensorflow opencv-python -q\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.cluster import KMeans\n",
        "from hmmlearn import hmm\n",
        "from fuzzywuzzy import process\n",
        "from math import log2\n",
        "import math\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "# File paths\n",
        "INS_CSV = '/content/inscriptions.csv'\n",
        "JSON_MAP = '/content/seal_id_and_image_mapping.json'\n",
        "IMG_DIR = '/content/seal_images/seal_images'\n",
        "OUTPUT_DIR = '/content/sign_crops'\n",
        "\n",
        "# Load data\n",
        "with open(JSON_MAP) as f:\n",
        "    image_map = json.load(f)\n",
        "\n",
        "df = pd.read_csv(INS_CSV)\n",
        "df_complete = df[df['complete'] == 'Y'].copy()\n",
        "\n",
        "# Seal prefix mapping\n",
        "site_prefix_map = {\n",
        "    'Alamgirpur': 'Agr', 'Allahdino': 'Ad', 'Harappa': 'H', 'Mohenjo-daro': 'M',\n",
        "    'Dholavira': 'D', 'Lothal': 'L', 'Kalibangan': 'K', 'Amri': 'Amri',\n",
        "    'Banawali': 'B', 'Chanhu-daro': 'C'\n",
        "}\n",
        "\n",
        "def compute_seal_key(row):\n",
        "    if pd.notna(row.get('cisi')) and row['cisi'] != '-':\n",
        "        return str(row['cisi']).split('.')[0]\n",
        "    site_prefix = site_prefix_map.get(row['site'], 'H')\n",
        "    return f\"{site_prefix}-{int(row['id'])}\"\n",
        "\n",
        "df_complete['seal_key'] = df_complete.apply(compute_seal_key, axis=1)\n",
        "df_complete = df_complete[df_complete['seal_key'].isin(image_map)]\n",
        "\n",
        "# Parse and normalize sequences\n",
        "def normalize_sign(s):\n",
        "    if s.startswith('002'): return '002'\n",
        "    if s.startswith('861'): return '861'\n",
        "    return s\n",
        "\n",
        "def parse_sequence(text):\n",
        "    if not isinstance(text, str): return []\n",
        "    raw = [s for s in text.strip('+').split('-') if s not in ('000', '999')]\n",
        "    return [normalize_sign(s) for s in raw]\n",
        "\n",
        "sequences = [parse_sequence(row['text']) for _, row in df_complete.iterrows()]\n",
        "sequences = [seq for seq in sequences if seq]\n",
        "\n",
        "# Sign vocabulary\n",
        "all_signs = sorted({s for seq in sequences for s in seq})\n",
        "sign_to_idx = {s: i for i, s in enumerate(all_signs)}\n",
        "idx_to_sign = {i: s for s, i in sign_to_idx.items()}\n",
        "\n",
        "# Co-occurrence matrix for clustering\n",
        "N = len(all_signs)\n",
        "co_occur = np.zeros((N, N), int)\n",
        "for seq in sequences:\n",
        "    for a, b in zip(seq, seq[1:]):\n",
        "        co_occur[sign_to_idx[a], sign_to_idx[b]] += 1\n",
        "\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(co_occur)\n",
        "sign_to_cluster = {s: kmeans.labels_[sign_to_idx[s]] for s in all_signs}\n",
        "\n",
        "# HMM Training\n",
        "def train_hmm(sequences, sign_to_cluster, n_states=5):\n",
        "    cluster_seqs = [[sign_to_cluster[s] for s in seq] for seq in sequences]\n",
        "    X = np.concatenate(cluster_seqs).reshape(-1, 1)\n",
        "    lengths = [len(seq) for seq in cluster_seqs]\n",
        "    model = hmm.MultinomialHMM(n_components=n_states, n_iter=100, random_state=42)\n",
        "    model.fit(X, lengths)\n",
        "    return model\n",
        "\n",
        "# RNN Training\n",
        "def train_rnn(sequences, sign_to_idx, max_len=10, emb=64, lstm_u=128, epochs=15):\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(1, len(seq)):\n",
        "            X.append([sign_to_idx[s] for s in seq[:i]])\n",
        "            y.append(sign_to_idx[seq[i]])\n",
        "    X_pad = pad_sequences(X, maxlen=max_len, padding='pre', dtype='int32')\n",
        "    y_arr = np.array(y, dtype='int32')\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=len(sign_to_idx), output_dim=emb),\n",
        "        Bidirectional(LSTM(lstm_u, return_sequences=False)),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(sign_to_idx), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_pad, y_arr, epochs=epochs, batch_size=32, verbose=1)\n",
        "    return model\n",
        "\n",
        "# Sequence generation\n",
        "def generate_sequence(model, seed_seq, sign_to_idx, idx_to_sign, max_len=10, steps=5):\n",
        "    seed = [normalize_sign(s) for s in seed_seq]\n",
        "    seq = [sign_to_idx.get(s, 0) for s in seed]\n",
        "    for _ in range(steps):\n",
        "        padded = pad_sequences([seq], maxlen=max_len, padding='pre', dtype='int32')\n",
        "        pred = model.predict(padded, verbose=0)\n",
        "        seq.append(int(np.argmax(pred)))\n",
        "    return [idx_to_sign[i] for i in seq]\n",
        "\n",
        "# Positional Entropy\n",
        "def compute_positional_entropy(sequences, all_signs):\n",
        "    pos_counts = defaultdict(lambda: {'start': 0, 'end': 0, 'middle': 0})\n",
        "    for seq in sequences:\n",
        "        if len(seq) == 0:\n",
        "            continue\n",
        "        pos_counts[seq[0]]['start'] += 1\n",
        "        if len(seq) > 1:\n",
        "            pos_counts[seq[-1]]['end'] += 1\n",
        "            for s in seq[1:-1]:\n",
        "                pos_counts[s]['middle'] += 1\n",
        "        else:\n",
        "            pos_counts[seq[0]]['end'] += 1\n",
        "    entropies = {}\n",
        "    for s in all_signs:\n",
        "        counts = pos_counts[s]\n",
        "        total = sum(counts.values())\n",
        "        if total == 0:\n",
        "            entropies[s] = 0\n",
        "            continue\n",
        "        probs = [count / total for count in counts.values() if count > 0]\n",
        "        entropy = -sum(p * math.log2(p) for p in probs)\n",
        "        entropies[s] = entropy\n",
        "    return entropies\n",
        "\n",
        "# PMI Calculation\n",
        "def compute_pmi(sequences):\n",
        "    pair_counts = Counter()\n",
        "    single_counts = Counter()\n",
        "    total_pairs = 0\n",
        "    for seq in sequences:\n",
        "        for i in range(len(seq) - 1):\n",
        "            a, b = seq[i], seq[i+1]\n",
        "            pair_counts[(a, b)] += 1\n",
        "            single_counts[a] += 1\n",
        "            single_counts[b] += 1\n",
        "            total_pairs += 1\n",
        "    pmi = {}\n",
        "    for (a, b), count in pair_counts.items():\n",
        "        if single_counts[a] > 0 and single_counts[b] > 0:\n",
        "            pmi[(a, b)] = log2((count * total_pairs) / (single_counts[a] * single_counts[b]))\n",
        "    return sorted(pmi.items(), key=lambda x: -x[1])\n",
        "\n",
        "# Cluster Analysis\n",
        "def analyze_clusters(pmi_pairs, sign_to_cluster):\n",
        "    within_cluster_pmi = []\n",
        "    across_cluster_pmi = []\n",
        "    pmi_dict = {pair: val for pair, val in pmi_pairs}\n",
        "    for (a, b), pmi in pmi_dict.items():\n",
        "        if sign_to_cluster.get(a, -1) == sign_to_cluster.get(b, -1):\n",
        "            within_cluster_pmi.append(pmi)\n",
        "        else:\n",
        "            across_cluster_pmi.append(pmi)\n",
        "    return np.mean(within_cluster_pmi) if within_cluster_pmi else 0, np.mean(across_cluster_pmi) if across_cluster_pmi else 0\n",
        "\n",
        "# Sign Panel Cropping\n",
        "def crop_sign_panels(img_dir, output_dir, df_complete):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for _, row in df_complete.iterrows():\n",
        "        key = row['seal_key']\n",
        "        imgs = image_map.get(key, [])\n",
        "        for fname in imgs:\n",
        "            src = os.path.join(img_dir, fname)\n",
        "            if not os.path.exists(src): continue\n",
        "            img = cv2.imread(src)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            edges = cv2.Canny(gray, 50, 150)\n",
        "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
        "            for i, cnt in enumerate(contours):\n",
        "                x, y, w, h = cv2.boundingRect(cnt)\n",
        "                crop = img[y:y+h, x:x+w]\n",
        "                out_path = os.path.join(output_dir, f\"{key}_{os.path.splitext(fname)[0]}_crop{i}.png\")\n",
        "                cv2.imwrite(out_path, crop)\n",
        "\n",
        "# RNN Sequence Analysis\n",
        "def analyze_rnn_sequences(rnn_model, sequences, sign_to_idx, idx_to_sign):\n",
        "    real_starts = Counter(seq[0] for seq in sequences if seq)\n",
        "    real_ends = Counter(seq[-1] for seq in sequences if seq)\n",
        "    real_bigrams = Counter((seq[i], seq[i+1]) for seq in sequences for i in range(len(seq)-1))\n",
        "\n",
        "    generated_seqs = []\n",
        "    for _ in range(100):\n",
        "        seed = [np.random.choice(all_signs)]\n",
        "        gen_seq = generate_sequence(rnn_model, seed, sign_to_idx, idx_to_sign)\n",
        "        generated_seqs.append(gen_seq)\n",
        "\n",
        "    gen_starts = Counter(seq[0] for seq in generated_seqs)\n",
        "    gen_ends = Counter(seq[-1] for seq in generated_seqs)\n",
        "    gen_bigrams = Counter((seq[i], seq[i+1]) for seq in generated_seqs for i in range(len(seq)-1))\n",
        "\n",
        "    print(\"Top 5 real starting signs:\", real_starts.most_common(5))\n",
        "    print(\"Top 5 generated starting signs:\", gen_starts.most_common(5))\n",
        "    print(\"Top 5 real ending signs:\", real_ends.most_common(5))\n",
        "    print(\"Top 5 generated ending signs:\", gen_ends.most_common(5))\n",
        "    print(\"Top 5 real bigrams:\", real_bigrams.most_common(5))\n",
        "    print(\"Top 5 generated bigrams:\", gen_bigrams.most_common(5))\n",
        "\n",
        "# Main Execution\n",
        "print(\"== IVS Analysis Pipeline ==\")\n",
        "print(f\"Training set size: {len(sequences)} inscriptions\")\n",
        "hmm_model = train_hmm(sequences, sign_to_cluster)\n",
        "rnn_model = train_rnn(sequences, sign_to_idx)\n",
        "\n",
        "# Entropy analysis\n",
        "positional_entropies = compute_positional_entropy(sequences, all_signs)\n",
        "sorted_signs = sorted(positional_entropies.items(), key=lambda x: -x[1])\n",
        "print(\"\\nTop 10 signs by positional entropy (likely content signs):\")\n",
        "for s, h in sorted_signs[:10]:\n",
        "    print(f\"{s}: H = {h:.3f}\")\n",
        "\n",
        "# PMI analysis\n",
        "pmi_pairs = compute_pmi(sequences)\n",
        "print(\"\\nTop 10 2-grams by PMI (likely fixed phrases):\")\n",
        "for (a, b), val in pmi_pairs[:10]:\n",
        "    print(f\"({a}, {b}): PMI = {val:.2f}\")\n",
        "\n",
        "# Cluster analysis\n",
        "within_pmi, across_pmi = analyze_clusters(pmi_pairs, sign_to_cluster)\n",
        "print(f\"\\nAverage PMI within clusters: {within_pmi:.2f}\")\n",
        "print(f\"Average PMI across clusters: {across_pmi:.2f}\")\n",
        "\n",
        "# RNN sequence analysis\n",
        "print(\"\\nRNN Sequence Analysis:\")\n",
        "analyze_rnn_sequences(rnn_model, sequences, sign_to_idx, idx_to_sign)\n",
        "\n",
        "# Crop sign panels\n",
        "crop_sign_panels(IMG_DIR, OUTPUT_DIR, df_complete)\n",
        "print(f\"\\nCropped sign panels saved to {OUTPUT_DIR}\")\n",
        "print(\"== Analysis Complete ==\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tLZrbUqTTyn",
        "outputId": "c6426919-03d6-4d12-f4d1-9ac7b0557d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:hmmlearn.hmm:MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
            "https://github.com/hmmlearn/hmmlearn/issues/335\n",
            "https://github.com/hmmlearn/hmmlearn/issues/340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== IVS Analysis Pipeline ==\n",
            "Training set size: 2229 inscriptions\n",
            "Epoch 1/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - accuracy: 0.0510 - loss: 5.4623\n",
            "Epoch 2/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - accuracy: 0.0920 - loss: 4.7692\n",
            "Epoch 3/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.1403 - loss: 4.2976\n",
            "Epoch 4/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.1723 - loss: 4.0626\n",
            "Epoch 5/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.2220 - loss: 3.8043\n",
            "Epoch 6/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.2536 - loss: 3.5209\n",
            "Epoch 7/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.2653 - loss: 3.4337\n",
            "Epoch 8/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - accuracy: 0.2912 - loss: 3.2749\n",
            "Epoch 9/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - accuracy: 0.3027 - loss: 3.1291\n",
            "Epoch 10/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3288 - loss: 3.0204\n",
            "Epoch 11/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.3437 - loss: 2.9316\n",
            "Epoch 12/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.3592 - loss: 2.7994\n",
            "Epoch 13/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.3672 - loss: 2.7446\n",
            "Epoch 14/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.3665 - loss: 2.6815\n",
            "Epoch 15/15\n",
            "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.3785 - loss: 2.6159\n",
            "\n",
            "Top 10 signs by positional entropy (likely content signs):\n",
            "006: H = 1.585\n",
            "064: H = 1.585\n",
            "103: H = 1.585\n",
            "143: H = 1.585\n",
            "242: H = 1.585\n",
            "244: H = 1.585\n",
            "285: H = 1.585\n",
            "324: H = 1.585\n",
            "710: H = 1.585\n",
            "165: H = 1.580\n",
            "\n",
            "Top 10 2-grams by PMI (likely fixed phrases):\n",
            "(718, 815): PMI = 12.71\n",
            "(749, 479): PMI = 12.71\n",
            "(833, 528): PMI = 11.71\n",
            "(865, 685/226): PMI = 11.71\n",
            "(251, 073): PMI = 11.71\n",
            "(160, 363): PMI = 11.71\n",
            "(561, 586): PMI = 11.13\n",
            "(127, 381): PMI = 11.13\n",
            "(901, 620): PMI = 11.13\n",
            "(307, 762): PMI = 10.71\n",
            "\n",
            "Average PMI within clusters: 5.84\n",
            "Average PMI across clusters: 1.16\n",
            "\n",
            "RNN Sequence Analysis:\n",
            "Top 5 real starting signs: [('740', 643), ('400', 189), ('700', 179), ('520', 145), ('390', 69)]\n",
            "Top 5 generated starting signs: [('257', 3), ('405', 2), ('689', 2), ('004/740', 2), ('179', 2)]\n",
            "Top 5 real ending signs: [('032', 113), ('033', 110), ('817', 105), ('820', 86), ('861', 79)]\n",
            "Top 5 generated ending signs: [('861', 21), ('575', 15), ('002', 8), ('165', 8), ('820', 5)]\n",
            "Top 5 real bigrams: [(('400', '740'), 104), (('002', '817'), 93), (('002', '861'), 89), (('700', '033'), 87), (('740', '176'), 73)]\n",
            "Top 5 generated bigrams: [(('002', '861'), 54), (('740', '100'), 15), (('335', '575'), 15), (('700', '033'), 14), (('033', '711'), 14)]\n",
            "\n",
            "Cropped sign panels saved to /content/sign_crops\n",
            "== Analysis Complete ==\n"
          ]
        }
      ]
    }
  ]
}